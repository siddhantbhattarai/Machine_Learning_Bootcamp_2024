{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e4a06a-7ae8-4cd3-b7ca-8a8cb9c99d77",
   "metadata": {},
   "source": [
    "### **Module 2: Data Wrangling and Manipulation**\n",
    "Students will learn how to filter, transform, and combine data for analysis.\n",
    "\n",
    "#### **Topics:**\n",
    "- **Selecting and Filtering Data:**\n",
    "  - Conditional selection (`boolean indexing`).\n",
    "  - Filtering rows/columns based on conditions.\n",
    "  \n",
    "- **Sorting Data:**\n",
    "  - Sorting by index or values using `sort_values()` and `sort_index()`.\n",
    "  \n",
    "- **Renaming Columns:**\n",
    "  - Renaming columns using `rename()`.\n",
    "  \n",
    "- **Adding/Removing Columns:**\n",
    "  - Creating new columns from existing data.\n",
    "  - Dropping columns or rows using `drop()`.\n",
    "\n",
    "- **Data Transformation:**\n",
    "  - Applying functions with `apply()` and `map()`.\n",
    "  - Using lambda functions for custom transformations.\n",
    "  \n",
    "- **Handling Duplicates:**\n",
    "  - Detecting and removing duplicate rows using `drop_duplicates()`.\n",
    "\n",
    "#### **Hands-on Lab:**\n",
    "- Filter a dataset based on specific conditions (e.g., values greater than a threshold).\n",
    "- Sort a dataset by multiple columns.\n",
    "- Create new columns by applying transformations to existing ones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b256442-168e-411a-a5d3-96c7f1fbad1c",
   "metadata": {},
   "source": [
    "## **Pandas Data Wrangling and Manipulation Notes with Hands-on Exercises**\n",
    "\n",
    "### **Overview:**\n",
    "In this module, you will learn how to filter, transform, and combine data for analysis using `pandas`. These operations are essential for cleaning and preparing data before performing analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d39c1-4fd1-413c-8f24-83b2e824b2e6",
   "metadata": {},
   "source": [
    "### **1. Selecting and Filtering Data**\n",
    "#### **Concepts:**\n",
    "- **Boolean Indexing**: Allows filtering of data based on conditions.\n",
    "- **Filtering Rows and Columns:** Apply conditions to extract subsets of data.\n",
    "\n",
    "#### **Key Methods:**\n",
    "- `df[condition]` – Filter rows based on condition.\n",
    "- `df.loc[]` – Select rows and columns using labels.\n",
    "- `df.iloc[]` – Select rows and columns using indices.\n",
    "\n",
    "#### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2966583-9a41-4aae-9556-29f61204e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Score  Passed\n",
      "0    Alice     85    True\n",
      "2  Charlie     92    True\n",
      "4      Eva     88    True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Score': [85, 78, 92, 70, 88],\n",
    "    'Passed': [True, True, True, False, True]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where score is greater than 80\n",
    "filtered_df = df[df['Score'] > 80]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c451e5-a7c5-4254-8132-b5bc56fc31f7",
   "metadata": {},
   "source": [
    "#### **Real-World Example:**\n",
    "**Use Case:** An e-commerce company wants to filter customers who spent more than $500 in a single transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858a30f5-bfc8-47ea-a15a-1f05a82f9e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  TransactionAmount Location\n",
      "1         102                600       LA\n",
      "3         104                750       NY\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample e-commerce dataset\n",
    "data = {\n",
    "    'CustomerID': [101, 102, 103, 104, 105],\n",
    "    'TransactionAmount': [250, 600, 300, 750, 200],\n",
    "    'Location': ['NY', 'LA', 'SF', 'NY', 'LA']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter customers who spent more than $500\n",
    "high_spending_customers = df[df['TransactionAmount'] > 500]\n",
    "print(high_spending_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8d981-bfc9-45c2-a053-0e19715615d5",
   "metadata": {},
   "source": [
    "#### **Exercise 1:**\n",
    "1. Load a dataset (e.g., a CSV file).\n",
    "2. Filter the data to display only rows where values in a specific column exceed a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bae8f0-6091-43cd-8c8b-1aa6510f363a",
   "metadata": {},
   "source": [
    "#### **Exercise 2:**\n",
    "1. Filter rows where employees have more than 10 years of experience.\n",
    "2. Filter rows where orders were placed from a specific city (e.g., \"Chicago\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f2a20-6281-4ce1-a02e-cb9d1c040e36",
   "metadata": {},
   "source": [
    "\n",
    "### **2. Sorting Data**\n",
    "#### **Concepts:**\n",
    "- Sorting helps in organizing data for better readability and analysis.\n",
    "- Sort by specific columns or indices.\n",
    "\n",
    "#### **Key Methods:**\n",
    "- `df.sort_values(by='column_name')` – Sort rows based on column values.\n",
    "- `df.sort_index()` – Sort rows by index.\n",
    "\n",
    "#### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d80383-7a6a-43ef-8d68-a96c202ad4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Score  Passed\n",
      "4      Eva     88    True\n",
      "3    David     70   False\n",
      "2  Charlie     92    True\n",
      "1      Bob     78    True\n",
      "0    Alice     85    True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Score': [85, 78, 92, 70, 88],\n",
    "    'Passed': [True, True, True, False, True]\n",
    "}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort by Score (ascending)\n",
    "sorted_df = df.sort_values(by='Score')\n",
    "\n",
    "# Sort by Name (descending)\n",
    "sorted_df_desc = df.sort_values(by='Name', ascending=False)\n",
    "print(sorted_df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a8569-b1fa-45b5-bcae-1f66e3fbfaed",
   "metadata": {},
   "source": [
    "#### **Real-World Example:**\n",
    "**Use Case:** A hotel booking system wants to sort customer bookings by check-in date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8aee43-7044-4fd0-aa25-02e0b5734895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BookingID CheckInDate  RoomType\n",
      "4        205  2025-01-09     Suite\n",
      "1        202  2025-01-10    Deluxe\n",
      "3        204  2025-01-11    Deluxe\n",
      "0        201  2025-01-12     Suite\n",
      "2        203  2025-01-15  Standard\n"
     ]
    }
   ],
   "source": [
    "# Sample booking dataset\n",
    "bookings = {\n",
    "    'BookingID': [201, 202, 203, 204, 205],\n",
    "    'CheckInDate': ['2025-01-12', '2025-01-10', '2025-01-15', '2025-01-11', '2025-01-09'],\n",
    "    'RoomType': ['Suite', 'Deluxe', 'Standard', 'Deluxe', 'Suite']\n",
    "}\n",
    "df_bookings = pd.DataFrame(bookings)\n",
    "\n",
    "# Sort by check-in date\n",
    "sorted_bookings = df_bookings.sort_values(by='CheckInDate')\n",
    "print(sorted_bookings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a64330-60ab-4fcb-8a57-44941cfb5861",
   "metadata": {},
   "source": [
    "#### **Exercise 3:**\n",
    "1. Sort a list of products based on their sales numbers in descending order.\n",
    "2. Sort employee records by department and then by name alphabetically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62106f-8d22-40b7-9004-45d83eec46af",
   "metadata": {},
   "source": [
    "#### **Exercise 4:**\n",
    "1. Sort the dataset based on multiple columns.\n",
    "2. Sort in descending order by one column and ascending order by another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f52914-e892-4047-8f71-d1c45381adc3",
   "metadata": {},
   "source": [
    "### **3. Renaming Columns**\n",
    "#### **Concepts:**\n",
    "- Useful when you want to make column names more descriptive or readable.\n",
    "\n",
    "#### **Key Methods:**\n",
    "- `df.rename(columns={'old_name': 'new_name'})` – Rename specific columns.\n",
    "\n",
    "#### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34079c0a-7413-49b7-bfb7-3ba79264cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Exam Score  Passed\n",
      "0    Alice          85    True\n",
      "1      Bob          78    True\n",
      "2  Charlie          92    True\n",
      "3    David          70   False\n",
      "4      Eva          88    True\n"
     ]
    }
   ],
   "source": [
    "# Rename column 'Score' to 'Exam Score'\n",
    "renamed_df = df.rename(columns={'Score': 'Exam Score'})\n",
    "print(renamed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2a726-9f37-4537-ad3c-dfa13e39f5e1",
   "metadata": {},
   "source": [
    "#### **Real-World Example:**\n",
    "**Use Case:** A company wants to rename columns for a payroll report to follow the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ae9c9a-666b-49f2-9a97-3e0e3d21f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  AnnualSalary  TaxPercentage\n",
      "0           1         50000           0.20\n",
      "1           2         70000           0.22\n",
      "2           3         65000           0.18\n",
      "3           4         58000           0.21\n"
     ]
    }
   ],
   "source": [
    "# Sample payroll data\n",
    "payroll_data = {\n",
    "    'EmpID': [1, 2, 3, 4],\n",
    "    'SalaryUSD': [50000, 70000, 65000, 58000],\n",
    "    'TaxRate': [0.20, 0.22, 0.18, 0.21]\n",
    "}\n",
    "df_payroll = pd.DataFrame(payroll_data)\n",
    "\n",
    "# Rename columns\n",
    "renamed_df = df_payroll.rename(columns={'EmpID': 'EmployeeID', 'SalaryUSD': 'AnnualSalary', 'TaxRate': 'TaxPercentage'})\n",
    "print(renamed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5cbf1-9953-4408-bbc3-93a580cfd55b",
   "metadata": {},
   "source": [
    "#### **Exercise 5:**\n",
    "1. Rename columns in a student grade report to more descriptive names.\n",
    "2. Rename columns in a product inventory to include units (e.g., \"Price\" to \"Price (USD)\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736d570-cf07-4281-8e4a-496f507b1682",
   "metadata": {},
   "source": [
    "#### **Exercise 6:**\n",
    "1. Rename columns to have consistent naming conventions (e.g., all lowercase).\n",
    "2. Rename multiple columns at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1697d18-48e0-4516-9814-fb3eb35e8408",
   "metadata": {},
   "source": [
    "### **4. Adding and Removing Columns**\n",
    "#### **Concepts:**\n",
    "- Add new columns derived from existing columns.\n",
    "- Remove unnecessary columns or rows.\n",
    "\n",
    "#### **Key Methods:**\n",
    "- `df['new_column'] = ...` – Add a new column.\n",
    "- `df.drop(columns=['column_name'])` – Drop specific columns.\n",
    "- `df.drop(index=[index_number])` – Drop specific rows.\n",
    "\n",
    "#### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf39ba3-92f1-4fdd-b351-0bc48c8627e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Score Grade\n",
      "0    Alice     85     A\n",
      "1      Bob     78     B\n",
      "2  Charlie     92    A+\n",
      "3    David     70     C\n",
      "4      Eva     88    B+\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Grade'\n",
    "df['Grade'] = ['A', 'B', 'A+', 'C', 'B+']\n",
    "\n",
    "# Drop the column 'Passed'\n",
    "df = df.drop(columns=['Passed'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15f179-7c08-40ef-a5af-7f3a0fcb6d8f",
   "metadata": {},
   "source": [
    "#### **Real-World Example:**\n",
    "**Use Case:** An airline adds a column indicating whether a flight is domestic or international based on destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff913ec-6f76-409e-a495-2fafeff0d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FlightNumber Destination  Duration     FlightType\n",
      "0        AA123    New York       180       Domestic\n",
      "1        BA456      London       420  International\n",
      "2        UA789     Chicago       200       Domestic\n",
      "\n",
      "\n",
      "  FlightNumber Destination     FlightType\n",
      "0        AA123    New York       Domestic\n",
      "1        BA456      London  International\n",
      "2        UA789     Chicago       Domestic\n"
     ]
    }
   ],
   "source": [
    "# Sample flight data\n",
    "flights = {\n",
    "    'FlightNumber': ['AA123', 'BA456', 'UA789'],\n",
    "    'Destination': ['New York', 'London', 'Chicago'],\n",
    "    'Duration': [180, 420, 200]\n",
    "}\n",
    "df_flights = pd.DataFrame(flights)\n",
    "\n",
    "# Add new column for flight type\n",
    "df_flights['FlightType'] = df_flights['Destination'].apply(lambda x: 'International' if x == 'London' else 'Domestic')\n",
    "print(df_flights)\n",
    "print(\"\\n\")\n",
    "# Remove Duration column\n",
    "df_flights = df_flights.drop(columns=['Duration'])\n",
    "print(df_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089851a1-68b4-40c9-9cdb-d5cf70d9472d",
   "metadata": {},
   "source": [
    "#### **Exercise 7:**\n",
    "1. Add a new column based on the values of other columns (e.g., calculate a percentage).\n",
    "2. Drop rows based on a condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd499f-c3bb-433a-9d48-88e4f98a7ee6",
   "metadata": {},
   "source": [
    "#### **Exercise 8:**\n",
    "1. Add a column in a sales dataset to calculate total revenue (quantity * price).\n",
    "2. Remove columns related to legacy data that are no longer needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029ff3f-ecd4-41bc-bdc1-eb88404170b1",
   "metadata": {},
   "source": [
    "### **5. Data Transformation**\n",
    "#### **Concepts:**\n",
    "- Applying functions to transform data.\n",
    "- Lambda functions allow for custom, inline transformations.\n",
    "\n",
    "#### **Key Methods:**\n",
    "- `df.apply(func)` – Apply a function to rows or columns.\n",
    "- `df['column'].map(func)` – Apply a function element-wise.\n",
    "\n",
    "#### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e240bab7-f110-4f4a-a7d4-c5b008961333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Score Grade Status\n",
      "0    Alice     85     A   Pass\n",
      "1      Bob     78     B   Pass\n",
      "2  Charlie     92    A+   Pass\n",
      "3    David     70     C   Fail\n",
      "4      Eva     88    B+   Pass\n",
      "\n",
      "\n",
      "      Name  Score Grade Status  Score_Updated\n",
      "0    Alice     85     A   Pass          89.25\n",
      "1      Bob     78     B   Pass          81.90\n",
      "2  Charlie     92    A+   Pass          96.60\n",
      "3    David     70     C   Fail          73.50\n",
      "4      Eva     88    B+   Pass          92.40\n"
     ]
    }
   ],
   "source": [
    "# Convert scores to pass/fail status\n",
    "def pass_fail(score):\n",
    "    return 'Pass' if score >= 75 else 'Fail'\n",
    "\n",
    "df['Status'] = df['Score'].apply(pass_fail)\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "# Using lambda function to increase scores by 5%\n",
    "df['Score_Updated'] = df['Score'].map(lambda x: x * 1.05)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec501c77-cac5-4488-b3e9-3ee6af5dc43b",
   "metadata": {},
   "source": [
    "#### **Real-World Example:**\n",
    "**Use Case:** A healthcare system needs to calculate BMI (Body Mass Index) for patients based on their height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520ad8c0-c8fc-40e5-82c6-18c8fee1bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PatientID  WeightKg  HeightM        BMI\n",
      "0        101        70     1.75  22.857143\n",
      "1        102        85     1.82  25.661152\n",
      "2        103        60     1.60  23.437500\n"
     ]
    }
   ],
   "source": [
    "# Sample healthcare dataset\n",
    "patients = {\n",
    "    'PatientID': [101, 102, 103],\n",
    "    'WeightKg': [70, 85, 60],\n",
    "    'HeightM': [1.75, 1.82, 1.60]\n",
    "}\n",
    "df_patients = pd.DataFrame(patients)\n",
    "\n",
    "# Add BMI column\n",
    "df_patients['BMI'] = df_patients.apply(lambda row: row['WeightKg'] / (row['HeightM'] ** 2), axis=1)\n",
    "print(df_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f2907-931e-4970-a33a-29cc1a3f81b3",
   "metadata": {},
   "source": [
    "#### **Exercise 9:**\n",
    "1. Create a new column that applies a mathematical operation on existing columns.\n",
    "2. Use `apply()` to categorize values based on conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae3d63-abd3-4b8e-910b-792c2f150fa8",
   "metadata": {},
   "source": [
    "#### **Exercise 10:**\n",
    "1. Apply a transformation to categorize customer ratings into \"Low\", \"Medium\", and \"High\".\n",
    "2. Use `map()` to convert temperatures from Celsius to Fahrenheit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87d624-c06f-442d-a43b-66709f242e76",
   "metadata": {},
   "source": [
    "### **6. Handling Duplicates**\n",
    "#### **Concepts:**\n",
    "- Detecting and removing duplicate rows.\n",
    "\n",
    "#### **Key Methods:**\n",
    "- `df.duplicated()` – Returns a Boolean Series indicating duplicate rows.\n",
    "- `df.drop_duplicates()` – Removes duplicate rows.\n",
    "\n",
    "#### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3891aee-28e7-46ce-82ca-af42473bcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "      Name  Score\n",
      "0    Alice     85\n",
      "1      Bob     78\n",
      "2  Charlie     92\n",
      "4      Eva     88\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame with duplicates\n",
    "data_dup = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eva'],\n",
    "    'Score': [85, 78, 92, 85, 88]\n",
    "}\n",
    "df_dup = pd.DataFrame(data_dup)\n",
    "\n",
    "# Detect duplicates\n",
    "print(df_dup.duplicated())\n",
    "print(\"\\n\")\n",
    "# Remove duplicates\n",
    "df_no_duplicates = df_dup.drop_duplicates()\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76dc12-4eb6-4335-94de-afb9596a0c11",
   "metadata": {},
   "source": [
    "#### **Real-World Example:**\n",
    "**Use Case:** A streaming service wants to ensure no duplicate subscription records exist in their system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff5ce8c-3372-405c-8d13-259aca796f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "   UserID SubscriptionPlan  DateJoined\n",
      "0    1001          Premium  2025-01-01\n",
      "1    1002            Basic  2025-01-02\n",
      "2    1003          Premium  2025-01-03\n"
     ]
    }
   ],
   "source": [
    "# Sample subscription data\n",
    "subscriptions = {\n",
    "    'UserID': [1001, 1002, 1003, 1001],\n",
    "    'SubscriptionPlan': ['Premium', 'Basic', 'Premium', 'Premium'],\n",
    "    'DateJoined': ['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-01']\n",
    "}\n",
    "df_subscriptions = pd.DataFrame(subscriptions)\n",
    "\n",
    "# Detect duplicates\n",
    "print(df_subscriptions.duplicated())\n",
    "print(\"\\n\")\n",
    "# Remove duplicates\n",
    "df_unique_subscriptions = df_subscriptions.drop_duplicates()\n",
    "print(df_unique_subscriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4a140-6660-4067-ab88-941a3519527d",
   "metadata": {},
   "source": [
    "#### **Exercise 11:**\n",
    "1. Identify duplicate rows in your dataset.\n",
    "2. Remove duplicates and verify the shape of the DataFrame before and after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd6357-a376-4474-8b71-d64fc0eac356",
   "metadata": {},
   "source": [
    "#### **Exercise 6:**\n",
    "1. Identify duplicate entries in an event registration dataset.\n",
    "2. Remove duplicate product listings from an inventory and count the number of unique products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54c2c3-6ab6-4198-8e17-5e59b449a20e",
   "metadata": {},
   "source": [
    "### **Summary:**\n",
    "- Filtering and selecting data allows you to isolate relevant rows or columns.\n",
    "- Sorting helps order the dataset for better analysis.\n",
    "- Renaming columns improves the readability of the dataset.\n",
    "- Adding/removing columns is useful for creating new features or removing irrelevant data.\n",
    "- Data transformation allows you to apply custom logic to modify data.\n",
    "- Handling duplicates ensures that data does not have unnecessary redundancy.\n",
    "\n",
    "By practicing these concepts and exercises, you will gain a strong foundation in data wrangling and manipulation using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72501432-3fb7-4a5b-b461-43f69efdc77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
