{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481b0e90-640d-49bb-aa11-a472c4c67322",
   "metadata": {},
   "source": [
    "### **Module 7: Working with Text Data**\n",
    "Text data often needs special handling, especially in ML applications like NLP. This module covers common text processing tasks.\n",
    "\n",
    "#### **Topics:**\n",
    "- **String Operations:**\n",
    "  - Using `str` accessor for string manipulation (e.g., `lower()`, `upper()`, `split()`, `contains()`).\n",
    "\n",
    "- **Removing Whitespace and Special Characters:**\n",
    "  - Stripping extra spaces and cleaning up special characters.\n",
    "  \n",
    "- **Extracting Information:**\n",
    "  - Extracting patterns from text using regular expressions.\n",
    "\n",
    "#### **Hands-on Lab:**\n",
    "- Clean a dataset's text column by removing special characters, converting text to lowercase, and splitting values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb281a-0b2b-4d86-958c-728db1f1bf5c",
   "metadata": {},
   "source": [
    "## **1. String Operations**\n",
    "\n",
    "### **Real-world Scenario 1: Customer Feedback Text Cleaning**  \n",
    "You have a **customer feedback dataset** where the text contains mixed case and random formatting. You want to standardize it by **converting everything to lowercase and checking if certain keywords** (e.g., \"refund\") are present.\n",
    "\n",
    "### **Example: String Manipulation in Feedback**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3007efa-ae35-4f28-afa3-35992e4b866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id                      feedback_cleaned  contains_refund\n",
      "0            1  excellent product! totally worth it!            False\n",
      "1            2           requesting a refund asap!!!             True\n",
      "2            3        delivery was late and damaged.            False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample customer feedback data\n",
    "feedback_data = {\n",
    "    'customer_id': [1, 2, 3],\n",
    "    'feedback': ['Excellent product! Totally worth it!', 'Requesting a REFUND ASAP!!!', 'delivery was Late and Damaged.']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(feedback_data)\n",
    "\n",
    "# Convert feedback to lowercase\n",
    "df['feedback_cleaned'] = df['feedback'].str.lower()\n",
    "\n",
    "# Check if the feedback contains the word \"refund\"\n",
    "df['contains_refund'] = df['feedback_cleaned'].str.contains('refund')\n",
    "\n",
    "print(df[['customer_id', 'feedback_cleaned', 'contains_refund']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664646d-4dd5-4b67-84b6-2efe42f46831",
   "metadata": {},
   "source": [
    "## **2. Removing Whitespace and Special Characters**\n",
    "\n",
    "### **Real-world Scenario 2: Cleaning Product Descriptions**  \n",
    "You have a dataset of **product descriptions** where some entries contain special characters (`#, @, *, $`) and extra spaces. You need to **strip whitespace and remove special characters** to clean the data.\n",
    "\n",
    "### **Example: Clean Product Descriptions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5bc431-0b5a-44d3-9f6b-59919061fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                description     description_cleaned\n",
      "0         101     Best-Quality Laptop@@       BestQuality Laptop\n",
      "1         102   High-Performance**Phone!    HighPerformancePhone\n",
      "2         103   Budget-Friendly*  Tablet  BudgetFriendly  Tablet\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample product descriptions\n",
    "product_data = {\n",
    "    'product_id': [101, 102, 103],\n",
    "    'description': ['  Best-Quality Laptop@@ ', ' High-Performance**Phone!', ' Budget-Friendly*  Tablet']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(product_data)\n",
    "\n",
    "# Remove special characters and strip whitespace\n",
    "df['description_cleaned'] = df['description'].str.replace(r'[^\\w\\s]', '', regex=True).str.strip()\n",
    "\n",
    "print(df[['product_id', 'description', 'description_cleaned']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e136b-b87d-4e43-9839-0090f867fa7f",
   "metadata": {},
   "source": [
    "## **3. Extracting Information**\n",
    "\n",
    "### **Real-world Scenario 3: Extracting Dates from Text**  \n",
    "You have a dataset of **support tickets** where the text contains dates. You want to **extract dates** from the text using regular expressions to create a new \"date\" column.\n",
    "\n",
    "### **Example: Extracting Dates from Support Tickets**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c68ed3f-7e41-45c7-9909-af74e60e2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticket_id                                        description extracted_date\n",
      "0        201             Reported on 2025-01-15: Server crashed     2025-01-15\n",
      "1        202       Issue detected on 2025/02/05 - Login failure     2025/02/05\n",
      "2        203  Maintenance scheduled for 2025.03.01 - Network...     2025.03.01\n"
     ]
    }
   ],
   "source": [
    "# Sample support tickets with dates in text\n",
    "ticket_data = {\n",
    "    'ticket_id': [201, 202, 203],\n",
    "    'description': ['Reported on 2025-01-15: Server crashed', \n",
    "                    'Issue detected on 2025/02/05 - Login failure', \n",
    "                    'Maintenance scheduled for 2025.03.01 - Network upgrade']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ticket_data)\n",
    "\n",
    "# Extract dates in different formats (YYYY-MM-DD, YYYY/MM/DD, YYYY.MM.DD)\n",
    "df['extracted_date'] = df['description'].str.extract(r'(\\d{4}[-/.]\\d{2}[-/.]\\d{2})')\n",
    "\n",
    "print(df[['ticket_id', 'description', 'extracted_date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7713d0-4aa4-4715-ba39-4f979662ac73",
   "metadata": {},
   "source": [
    "## **4. Full Hands-on Lab: Text Data Cleaning**  \n",
    "### **Scenario 4: Cleaning a Product Reviews Dataset**  \n",
    "You have a dataset of **product reviews** with issues such as special characters, mixed case, and extra spaces. You want to:\n",
    "1. **Remove special characters** and **extra spaces**.\n",
    "2. Convert reviews to **lowercase**.\n",
    "3. Split the cleaned review into **individual words**.\n",
    "\n",
    "### **Example: Cleaning and Splitting Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f174232c-bf57-4184-a430-dfeca61e838b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>split_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazing @ Quality! Phone   #Value for Money!</td>\n",
       "      <td>amazing  quality phone   value for money</td>\n",
       "      <td>[amazing, quality, phone, value, for, money]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Horrible** experience. Never again.</td>\n",
       "      <td>horrible experience never again</td>\n",
       "      <td>[horrible, experience, never, again]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Very SLOW delivery!!!  Disappointing.</td>\n",
       "      <td>very slow delivery  disappointing</td>\n",
       "      <td>[very, slow, delivery, disappointing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                         review  \\\n",
       "0          1   Amazing @ Quality! Phone   #Value for Money!   \n",
       "1          2            Horrible** experience. Never again.   \n",
       "2          3          Very SLOW delivery!!!  Disappointing.   \n",
       "\n",
       "                             cleaned_review  \\\n",
       "0  amazing  quality phone   value for money   \n",
       "1           horrible experience never again   \n",
       "2         very slow delivery  disappointing   \n",
       "\n",
       "                                   split_review  \n",
       "0  [amazing, quality, phone, value, for, money]  \n",
       "1          [horrible, experience, never, again]  \n",
       "2         [very, slow, delivery, disappointing]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample product reviews data\n",
    "reviews_data = {\n",
    "    'review_id': [1, 2, 3],\n",
    "    'review': [' Amazing @ Quality! Phone   #Value for Money!', 'Horrible** experience. Never again.', 'Very SLOW delivery!!!  Disappointing.']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Clean the review text\n",
    "df['cleaned_review'] = df['review'].str.replace(r'[^\\w\\s]', '', regex=True).str.lower().str.strip()\n",
    "\n",
    "# Split cleaned reviews into words\n",
    "df['split_review'] = df['cleaned_review'].str.split()\n",
    "\n",
    "display(df[['review_id', 'review', 'cleaned_review', 'split_review']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f173f2-57ee-4789-9622-5585a7ac0965",
   "metadata": {},
   "source": [
    "## **5. Hands-on Lab: Real-world Scenarios**  \n",
    "\n",
    "### **Scenario 5: Cleaning Emails for Spam Detection**  \n",
    "You have a dataset of **emails** where you need to clean the subject lines by **removing URLs, special characters, and extra spaces**, and converting the text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fab1f1-1273-46bc-9161-7305d5fab00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   email_id                        subject_line               cleaned_subject\n",
      "0         1  WIN BIG $$$ Visit http://promo.com                win big  visit\n",
      "1         2     Limited Offer!!! Click here NOW  limited offer click here now\n",
      "2         3           Your Invoice #12345 Ready      your invoice 12345 ready\n"
     ]
    }
   ],
   "source": [
    "# Sample email subject lines\n",
    "email_data = {\n",
    "    'email_id': [1, 2, 3],\n",
    "    'subject_line': ['WIN BIG $$$ Visit http://promo.com', 'Limited Offer!!! Click here NOW', 'Your Invoice #12345 Ready']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(email_data)\n",
    "\n",
    "# Remove URLs and special characters\n",
    "df['cleaned_subject'] = df['subject_line'].str.replace(r'http\\S+', '', regex=True)  # Remove URLs\n",
    "df['cleaned_subject'] = df['cleaned_subject'].str.replace(r'[^\\w\\s]', '', regex=True).str.lower().str.strip()\n",
    "\n",
    "print(df[['email_id', 'subject_line', 'cleaned_subject']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2caea7-6289-4fab-b130-75d2dce9c52a",
   "metadata": {},
   "source": [
    "### **Scenario 6: Extracting Phone Numbers from Text**  \n",
    "You have a dataset of **customer messages** where phone numbers are mentioned in different formats. You want to **extract the phone numbers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccb655f-e7b0-4e59-8b38-427e1603085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   message_id                              message extracted_phone\n",
      "0           1  Call me at 987-654-3210 for details    987-654-3210\n",
      "1           2          My number is (123) 456-7890  (123) 456-7890\n",
      "2           3                  Contact: 1234567890      1234567890\n"
     ]
    }
   ],
   "source": [
    "# Sample messages with phone numbers\n",
    "messages_data = {\n",
    "    'message_id': [1, 2, 3],\n",
    "    'message': ['Call me at 987-654-3210 for details', 'My number is (123) 456-7890', 'Contact: 1234567890']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(messages_data)\n",
    "\n",
    "# Extract phone numbers\n",
    "df['extracted_phone'] = df['message'].str.extract(r'(\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4})')\n",
    "\n",
    "print(df[['message_id', 'message', 'extracted_phone']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252645d-50d6-4d62-9580-3ad8742b01b9",
   "metadata": {},
   "source": [
    "### **Scenario 7: Identifying Spam Keywords**  \n",
    "You have a dataset of **user comments**. You need to **flag comments** that contain spammy keywords such as \"win\", \"offer\", or \"prize\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffbe454-563c-42fe-987b-901d23c9cc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   comment_id                            comment  is_spam\n",
      "0           1              You have WON a prize!     True\n",
      "1           2  Limited time OFFER available now!     True\n",
      "2           3            Happy with the product.    False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample user comments\n",
    "comments_data = {\n",
    "    'comment_id': [1, 2, 3],\n",
    "    'comment': ['You have WON a prize!', 'Limited time OFFER available now!', 'Happy with the product.']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comments_data)\n",
    "\n",
    "# Use non-capturing group (?:...) in the regex\n",
    "df['is_spam'] = df['comment'].str.lower().str.contains(r'\\b(?:win|offer|prize)\\b')\n",
    "\n",
    "print(df[['comment_id', 'comment', 'is_spam']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc46723-a2e9-496f-9cc6-0d76e995f310",
   "metadata": {},
   "source": [
    "### **Scenario 8: Cleaning Social Media Post Content**  \n",
    "You have a dataset of **social media posts** with hashtags, mentions, and emojis. You need to **remove hashtags, mentions (@username), and emojis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39cc9cc9-9e51-4162-b03b-1f1ce1bc4279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_id                      content          cleaned_content\n",
      "0        1    Great day! #happy @john 😊                Great day\n",
      "1        2  Just bought a new phone! 📱🎉  Just bought a new phone\n",
      "2        3           Lunch time! #yummy               Lunch time\n"
     ]
    }
   ],
   "source": [
    "# Sample social media posts\n",
    "social_media_data = {\n",
    "    'post_id': [1, 2, 3],\n",
    "    'content': ['Great day! #happy @john 😊', 'Just bought a new phone! 📱🎉', 'Lunch time! #yummy']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(social_media_data)\n",
    "\n",
    "# Remove hashtags, mentions, and emojis\n",
    "df['cleaned_content'] = df['content'].str.replace(r'@\\w+', '', regex=True)  # Remove mentions\n",
    "df['cleaned_content'] = df['cleaned_content'].str.replace(r'#\\w+', '', regex=True)  # Remove hashtags\n",
    "df['cleaned_content'] = df['cleaned_content'].str.replace(r'[^\\w\\s]', '', regex=True).str.strip()  # Remove emojis\n",
    "\n",
    "print(df[['post_id', 'content', 'cleaned_content']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0850cfe-b181-4d31-a118-a7b61da54b30",
   "metadata": {},
   "source": [
    "### **Scenario 9: Extracting Hashtags from Tweets**  \n",
    "You have a dataset of **tweets** and want to **extract hashtags** to analyze trending topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e4e1c9-7091-4f2d-92bb-3f2d0b693653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                               tweet                 hashtags\n",
      "0         1             #Python is amazing! #AI           [#Python, #AI]\n",
      "1         2  Learning #DataScience with #Python  [#DataScience, #Python]\n",
      "2         3                   No hashtags here!                       []\n"
     ]
    }
   ],
   "source": [
    "# Sample tweets\n",
    "tweet_data = {\n",
    "    'tweet_id': [1, 2, 3],\n",
    "    'tweet': ['#Python is amazing! #AI', 'Learning #DataScience with #Python', 'No hashtags here!']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(tweet_data)\n",
    "\n",
    "# Extract hashtags\n",
    "df['hashtags'] = df['tweet'].str.findall(r'#\\w+')\n",
    "\n",
    "print(df[['tweet_id', 'tweet', 'hashtags']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba7cbf-5ce0-4122-855b-0c6f72a13ea7",
   "metadata": {},
   "source": [
    "## **Summary of Examples:**\n",
    "\n",
    "| **Scenario**               | **Task**                                  | **Description**                                           |\n",
    "|----------------------------|-------------------------------------------|----------------------------------------------------------|\n",
    "| Customer Feedback Cleaning  | `str.lower()`, `contains()`                | Standardize case and check for keywords.                  |\n",
    "| Product Description Cleaning| `str.replace()`, `str.strip()`             | Remove special characters and trim whitespace.            |\n",
    "| Support Ticket Date Extraction | `str.extract()`                         | Extract dates in various formats using regex.             |\n",
    "| Product Reviews             | `str.split()`                              | Split cleaned reviews into individual words.              |\n",
    "| Spam Detection in Emails    | Regex for URLs and special characters      | Clean subject lines by removing URLs and special chars.   |\n",
    "| Extracting Phone Numbers    | Regex patterns for phone numbers           | Extract phone numbers from customer messages.             |\n",
    "| Spam Keywords in Comments   | `contains()`                               | Flag comments containing spammy keywords.                 |\n",
    "| Social Media Content        | `str.replace()` for hashtags and mentions  | Remove mentions, hashtags, and emojis.                    |\n",
    "| Hashtag Extraction          | `str.findall()`                            | Extract hashtags from tweets for trend analysis.          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed649cb-04b6-4682-9a87-be63d213aea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
